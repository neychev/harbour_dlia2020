{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Quantization Practice\n",
    "\n",
    "This tutorial implements [DoReFa-Net](https://arxiv.org/abs/1606.06160) weight and activation quantization scheme. Gradient quantization is not implemented, however is described in the original paper.\n",
    "\n",
    "Code inspiration is taken from randomly found [github](https://github.com/zzzxxxttt/pytorch_DoReFaNet) due to the fact that current notebook author has a lack of creativity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "batch_size = 256\n",
    "test_batch_size = 128\n",
    "epochs = 10\n",
    "lr = 1e-3\n",
    "weight_decay = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use MNIST dataset and evaluate one of the current state-of-the-art methods of CNN quantization.\n",
    "\n",
    "We will implement a simple CNN model yet capable of reaching high performance on MNIST.\n",
    "\n",
    "Then we will implement a quantized CNN capable of reaching same performance on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loading\n",
    "\n",
    "We are developing quantized neural networks, so we need to feed images into CNN in different manner:\n",
    "pixel absolute values are no longer needed to be less than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_signed_char(tensor):\n",
    "    # note that we convert image values from float32 range([-0.5, 0.5]) to signed char range [-128,127]\n",
    "    return torch.floor(255.0 * tensor)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.5,), (1, )),\n",
    "                       \n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (1, )),\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Training and Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, **kwargs):\n",
    "    log_interval = kwargs.get('log_interval', 10)\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(to_signed_char(data))\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, **kwargs):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(to_signed_char(data))\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Model\n",
    "\n",
    "Let's implement something really easy, __conv->bn->relu->pool__ will be enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.maxpool_2x2 = nn.MaxPool2d((2,2))\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc1 = nn.Linear(64, 10)\n",
    "        self.gmp = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool_2x2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.gmp(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch, log_interval=50)\n",
    "    test(model, device, test_loader)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantization Layers\n",
    "\n",
    "Not let's implement basic building blocks for DoReFa-Net quantization scheme.\n",
    "Firstly, we will need to implement uniform quantizer.\n",
    "\n",
    "Given real value $r\\in [0;1]$ uniform quantized value $r_0$ may be calculated:\n",
    "\n",
    "$r_0 = \\frac{1}{2^k-1} round((2^k-1) * r)$\n",
    "\n",
    "The calculated value may be saved as floating point number, or converted to fixed point representation by multiplying it on $2^{\\text{n_bits}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uniform_quantizer(n_bits):\n",
    "    class qfn(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, in_tensor):\n",
    "            if n_bits == 32:\n",
    "                # do not apply quantizer for full-bitwidth values\n",
    "                out_tensor = in_tensor\n",
    "            elif n_bits == 1:\n",
    "                # Binary Weight Net implementation\n",
    "                out_tensor = torch.sign(in_tensor)\n",
    "            else:\n",
    "                n = float(2 ** n_bits - 1)\n",
    "                out = torch.round(in_tensor * n) / n\n",
    "            return out\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output):\n",
    "            grad_input = grad_output.clone()\n",
    "            return grad_input\n",
    "    return qfn().apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will need separate quantization functions for weights and activations.\n",
    "For weights the following formula is implemented:\n",
    "$$\n",
    "r_0 = 2 \\cdot\\textit{quantize_k}(\\frac{tanh(r)}{2 * max|tanh(r)|} + \\frac{1}{2}) - 1\n",
    "$$\n",
    "For activations uniform quantization is applied, as defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class weight_quantize_fn(nn.Module):\n",
    "    def __init__(self, n_bits):\n",
    "        super(weight_quantize_fn, self).__init__()\n",
    "        assert n_bits <= 8 or n_bits == 32\n",
    "        self.n_bits = n_bits\n",
    "        self.value_range = 2 ** self.n_bits - 1\n",
    "        self.uniform_q = get_uniform_quantizer(n_bits)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.n_bits == 32:\n",
    "            weight_q = x\n",
    "        elif self.n_bits == 1:\n",
    "            E = x.abs().mean().detach()\n",
    "            weight_q = self.uniform_q(x / E) * E\n",
    "        else:\n",
    "            weight = x.tanh()\n",
    "            weight = weight / 2 / weight.abs().max() + 0.5\n",
    "            # weight_q = 2 * self.uniform_q(weight) - 1 # for original implementation with real values\n",
    "            weight_q = self.uniform_q(weight)\n",
    "            weight_q = self.value_range * weight_q - (self.value_range + 1) / 2\n",
    "        return weight_q\n",
    "\n",
    "\n",
    "class activation_quantize_fn(nn.Module):\n",
    "    def __init__(self, n_bits):\n",
    "        super(activation_quantize_fn, self).__init__()\n",
    "        assert n_bits <= 8 or n_bits == 32\n",
    "        self.n_bits = n_bits\n",
    "        self.uniform_q = get_uniform_quantizer(n_bits)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.n_bits == 32:\n",
    "            activation_q = x\n",
    "        else:\n",
    "            activation_q = (2 ** self.n_bits - 1) * self.uniform_q(torch.clamp(x, 0, 1))\n",
    "        return activation_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now our building blocks allow us to implement basic convolution and activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRFConv2d(nn.Conv2d):\n",
    "    def __init__(self, n_bits, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, bias=False):\n",
    "        super(DRFConv2d, self).__init__(in_channels, out_channels, kernel_size, stride,\n",
    "                                 padding, dilation, groups, bias)\n",
    "        self.n_bits = n_bits\n",
    "        self.quantize_fn = weight_quantize_fn(n_bits)\n",
    "\n",
    "    def forward(self, in_tensor, order=None):\n",
    "        weight_q = self.quantize_fn(self.weight)\n",
    "        return F.conv2d(in_tensor, weight_q, self.bias, self.stride,\n",
    "                  self.padding, self.dilation, self.groups)\n",
    "\n",
    "class DRFActivation(nn.Module):\n",
    "    def __init__(self, n_bits):\n",
    "        super(DRFActivation, self).__init__()\n",
    "        self.n_bits = n_bits\n",
    "        self.quantize_fn = activation_quantize_fn(n_bits)\n",
    "\n",
    "    def forward(self, in_tensor):\n",
    "        if self.n_bits >= 32:\n",
    "            return in_tensor\n",
    "        out_tensor = self.quantize_fn(in_tensor)\n",
    "        return out_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement the quantized CNN the same as the full-precision CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNet(nn.Module):\n",
    "    def __init__(self, n_bits=8):\n",
    "        super(QNet, self).__init__()\n",
    "        self.n_bits = n_bits\n",
    "        self.conv1 = nn.Sequential(\n",
    "            DRFConv2d(self.n_bits, 1, 32, 3, 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            DRFActivation(self.n_bits)\n",
    "        )\n",
    "        self.maxpool_2x2 = nn.MaxPool2d((2,2))\n",
    "        self.conv2 = nn.Sequential(\n",
    "            DRFConv2d(self.n_bits, 32, 64, 3, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            DRFActivation(self.n_bits)\n",
    "        )\n",
    "        self.fc1 = DRFConv2d(self.n_bits, 64, 10, 1)\n",
    "        self.gmp = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool_2x2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.gmp(x)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        output = x / 100000\n",
    "        output = F.log_softmax(output, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "qmodel = QNet().to(torch.device('cpu'))\n",
    "in_tensor = torch.floor(torch.from_numpy(np.random.randint(0,255,size=(28,28))).view(1, 1, 28, 28).type(torch.float)) - 127\n",
    "res = qmodel(in_tensor)\n",
    "print(res.detach().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = QNet().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch, log_interval=100)\n",
    "    test(model, device, test_loader)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
